{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US Coranvirus_Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of Coronavirus (COVID-19) Evolution and Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Import, clean and format confirmed Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Data Sources\n",
    "\n",
    "#### Source of data: https://raw.githubusercontent.com/CSSEGISandData, this is updated by John Hopkins Univiersity from a variety of government and NGO sources\n",
    "#### For full list of sources see: https://systems.jhu.edu/research/public-health/ncov/\n",
    "#### originally had been pulling directly from google sheets as per\n",
    "\n",
    "#### csv_url='http://spreadsheets.google.com/ccc?key=1UF2pSkFTURko2OvfHWWlFpDFAr1UxCBA4JLwlSP6KFo&output=csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1697471"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests as rs\n",
    "import pandas as pd\n",
    "\n",
    "#csv_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "\n",
    "#read cases\n",
    "\n",
    "csv_url='https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv'\n",
    "\n",
    "res=rs.get(url=csv_url)\n",
    "open('coronavirus_stats_confUS.csv', 'wb').write(res.content)\n",
    "\n",
    "#read_conf = pd.read_csv('/Users/neil.watt/Documents/PythonScripts/Coronavirus/coronavirus_stats_conf2.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "#read deaths\n",
    "csv_url='https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv'\n",
    "\n",
    "res=rs.get(url=csv_url)\n",
    "open('coronavirus_stats_deathUS.csv', 'wb').write(res.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Reading in cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#read_conf = pd.read_csv('/Users/neilwatt/Documents/Projects/Coronavirus/Coronavirus_Analysis/coronavirus_stats_confUS.csv', encoding = \"ISO-8859-1\")\n",
    "read_conf = pd.read_csv('/Users/neil.watt/Documents/PythonScripts/Coronavirus/coronavirus_stats_confUS.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "#replace blank province/state with nil\n",
    "read_conf['Province_State'].fillna('', inplace=True)\n",
    "\n",
    "#replace all other NaNs with 0\n",
    "read_conf.fillna(0, inplace=True)\n",
    "\n",
    "#create new name key column\n",
    "read_conf.insert(1, 'name', read_conf[\"Province_State\"].map(str))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_deaths = pd.read_csv('/Users/neil.watt/Documents/PythonScripts/Coronavirus/coronavirus_stats_deathUS.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "\n",
    "#replace blank province/state with nil\n",
    "read_deaths['Province_State'].fillna('', inplace=True)\n",
    "\n",
    "#replace all other NaNs with 0\n",
    "read_deaths.fillna(0, inplace=True)\n",
    "\n",
    "#create new name key column\n",
    "read_deaths.insert(1, 'name', read_deaths[\"Province_State\"].map(str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Formatting and Cleaning Data (Cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data in the CSV file needs to be re-worked and reshaped to facilitate convenient plotting.\n",
    "#### 1.  I first sliced the csv into two dataframes and then transposed the date columns (from column 5 onwards)\n",
    "#### 2. Next step was to rework the cases figures into a \"Cases\" column according to the Date column (which is created from the index date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#slice confirmed cases into two dfs in order to recombine transpose of the cases table with the regions\n",
    "\n",
    "read_conf_copy=read_conf.copy()\n",
    "\n",
    "#this creates a dataframe which is a slice with just the city rows (which will be replciated for each date)\n",
    "\n",
    "new_city=read_conf_copy.iloc[:,0:12]\n",
    "read_conf_copy=read_conf.copy()\n",
    "\n",
    "#this slices the date columns from the original\n",
    "\n",
    "#new_df2=read_conf_copy.iloc[:,6:]\n",
    "new_df2=read_conf_copy.iloc[:,12:]\n",
    "\n",
    "\n",
    "\n",
    "#transpose date and cases columnes\n",
    "new_df2_T=new_df2.T\n",
    "\n",
    "\n",
    "#number cities\n",
    "i_points=len(read_conf.index)\n",
    "\n",
    "#new_df2_T_1=new_df2_T.iloc[:,0:1]\n",
    "new_df2_T['Date'] = new_df2_T.index\n",
    "\n",
    "d = {}\n",
    "for i in range (0,i_points):\n",
    "    d[i]=new_df2_T.iloc[:,i].to_frame()\n",
    "    d[i].rename(columns={ d[i].columns[0]: \"Cases\" }, inplace = True)\n",
    "    d[i]['Date'] = d[i].index\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframes are subsequently re-combined and duplicates are eliminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#recombine dataframes\n",
    "\n",
    "dfs={}\n",
    "for i in range (0,i_points):\n",
    "\n",
    "\n",
    "#match with df1 based on column header\n",
    "    city_row=new_city.loc[i,:].to_frame()\n",
    "    city_row_T=city_row.T\n",
    "\n",
    "#needs to be repeated same number of times as date columns\n",
    "    n_times=len(d[i].index)\n",
    "    city_row_T2=pd.concat([city_row_T]*n_times)\n",
    "\n",
    "\n",
    "    d[i]['tmp'] = 1\n",
    "    city_row_T2['tmp'] = 1\n",
    "\n",
    "    dfs[i] = pd.merge(city_row_T2,d[i], on=['tmp'])\n",
    "    dfs[i] = dfs[i].drop('tmp', axis=1)\n",
    "    dfs[i]= dfs[i].drop_duplicates(subset='Date')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#append dataframes into master format\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "#in order to model number of days from onset, convert to datetime\n",
    "final_df['Date_proper'] = pd.to_datetime(final_df['Date'])\n",
    "\n",
    "#Create new days column based on number of days from first row\n",
    "final_df['Day']=((final_df['Date_proper']-final_df['Date_proper'].iloc[0]).dt.total_seconds())/(24*60*60)+1\n",
    "\n",
    "#create DoD delta cases\n",
    "#final_df['Delta_Cases']=((final_df['Cases']-final_df['Cases'].iloc[i-1]))\n",
    "\n",
    "#final_df_international['total_cases']=final_df_international['Cases'].groupby(final_df_international['Date']).transform('sum')\n",
    "\n",
    "\n",
    "#final_df['Delta_Cases']=((final_df['Cases']-final_df['Cases'].shift(1))).groupby(final_df['name']).transform('sum')\n",
    "\n",
    "\n",
    "final_df['Delta_Cases']=final_df['Cases'].groupby(final_df['name']).diff()\n",
    "\n",
    "\n",
    "final_df.to_csv(r'Coronavirus_cases_cleanedUS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Formatting and Cleaning Data (Deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slice confirmed cases into two dfs in order to recombine transpose of the cases table with the regions\n",
    "\n",
    "read_deaths_copy=read_deaths.copy()\n",
    "\n",
    "#this creates a dataframe which is a slice with just the city rows (which will be replciated for each date)\n",
    "\n",
    "new_citydeaths=read_deaths_copy.iloc[:,0:13]\n",
    "read_deaths_copy=read_deaths.copy()\n",
    "\n",
    "#this slices the date columns from the original\n",
    "\n",
    "#new_df2=read_conf_copy.iloc[:,6:]\n",
    "new_df2deaths=read_deaths_copy.iloc[:,13:]\n",
    "\n",
    "\n",
    "\n",
    "#transpose date and cases columnes\n",
    "new_df2_Tdeaths=new_df2deaths.T\n",
    "\n",
    "\n",
    "#number cities\n",
    "i_pointsdeaths=len(read_deaths.index)\n",
    "\n",
    "#new_df2_T_1=new_df2_T.iloc[:,0:1]\n",
    "new_df2_Tdeaths['Date'] = new_df2_Tdeaths.index\n",
    "\n",
    "d = {}\n",
    "for i in range (0,i_pointsdeaths):\n",
    "    d[i]=new_df2_Tdeaths.iloc[:,i].to_frame()\n",
    "    d[i].rename(columns={ d[i].columns[0]: \"deaths\" }, inplace = True)\n",
    "    d[i]['Date'] = d[i].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#recombine dataframes\n",
    "\n",
    "dfsdeaths={}\n",
    "for i in range (0,i_pointsdeaths):\n",
    "\n",
    "\n",
    "#match with df1 based on column header\n",
    "    city_rowdeaths=new_citydeaths.loc[i,:].to_frame()\n",
    "    city_row_Tdeaths=city_rowdeaths.T\n",
    "\n",
    "#needs to be repeated same number of times as date columns\n",
    "    n_times=len(d[i].index)\n",
    "    city_row_T2deaths=pd.concat([city_row_Tdeaths]*n_times)\n",
    "\n",
    "\n",
    "    d[i]['tmp'] = 1\n",
    "    city_row_T2deaths['tmp'] = 1\n",
    "\n",
    "    dfsdeaths[i] = pd.merge(city_row_T2deaths,d[i], on=['tmp'])\n",
    "    dfsdeaths[i] = dfsdeaths[i].drop('tmp', axis=1)\n",
    "    dfsdeaths[i]= dfsdeaths[i].drop_duplicates(subset='Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append dataframes into master format\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "final_dfdeaths = pd.concat(dfsdeaths, ignore_index=True)\n",
    "#in order to model number of days from onset, convert to datetime\n",
    "final_dfdeaths['Date_proper'] = pd.to_datetime(final_dfdeaths['Date'])\n",
    "\n",
    "#Create new days column based on number of days from first row\n",
    "final_dfdeaths['Day']=((final_dfdeaths['Date_proper']-final_dfdeaths['Date_proper'].iloc[0]).dt.total_seconds())/(24*60*60)+1\n",
    "\n",
    "#create DoD delta cases\n",
    "#final_df['Delta_Cases']=((final_df['Cases']-final_df['Cases'].iloc[i-1]))\n",
    "\n",
    "#final_df_international['total_cases']=final_df_international['Cases'].groupby(final_df_international['Date']).transform('sum')\n",
    "\n",
    "\n",
    "#final_df['Delta_Cases']=((final_df['Cases']-final_df['Cases'].shift(1))).groupby(final_df['name']).transform('sum')\n",
    "\n",
    "\n",
    "final_dfdeaths['Delta_Deaths']=final_dfdeaths['deaths'].groupby(final_dfdeaths['name']).diff()\n",
    "\n",
    "\n",
    "final_dfdeaths.to_csv(r'Coronavirus_deaths_cleanedUS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Cases by Geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df_MChina' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-8e1b3d8c7c43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m fig = px.scatter_geo(final_df_MChina , lat=\"Lat\",lon=\"Long\",\n\u001b[0m\u001b[0;32m      9\u001b[0m                     \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Cases\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                     \u001b[1;31m#size=\"Cases\",\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_df_MChina' is not defined"
     ]
    }
   ],
   "source": [
    "import  plotly.express as px\n",
    "#https://plot.ly/python-api-reference/generated/plotly.express.scatter_geo.html\n",
    "scale=0.1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = px.scatter_geo(final_df_MChina , lat=\"Lat\",lon=\"Long\",\n",
    "                    color=\"Cases\",\n",
    "                    #size=\"Cases\",\n",
    "                     size_max=70,\n",
    "                    size='Cases',\n",
    "                     #size=\"Cases\",\n",
    "                     title=\"Coronavirus Cases by Day (Mainland China))\",\n",
    "                     \n",
    "                   hover_name=\"name\", \n",
    "                     #labels=\"name\",\n",
    "                    color_continuous_scale=px.colors.sequential.RdBu[::-1],\n",
    "                     # color_continuous_scale=px.colors.sequential.Plasma,\n",
    "                     #plotly.express.colors.diverging\n",
    "                    animation_frame=\"Date\"\n",
    "                    \n",
    "                    \n",
    "                    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot of international cases\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.line(final_df_international,title=\"International Cases\", x=\"Date\", y=\"Cases\", color=\"name\", line_group=\"name\", hover_name=\"name\",render_mode=\"svg\")\n",
    "fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"name=\", \"\")))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_italy=final_df_international[final_df_international['Country/Region']=='Italy']\n",
    "                                \n",
    "df_italy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_international.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_MChina.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non Mainland China only\n",
    "\n",
    "import  plotly.express as px\n",
    "#https://plot.ly/python-api-reference/generated/plotly.express.scatter_geo.html\n",
    "\n",
    "\n",
    "final_df_US_specific=final_df[(final_df['Country/Region']=='US') ]\n",
    "\n",
    "\n",
    "fig = px.scatter_geo(final_df_US_specific , lat=\"Lat\",lon=\"Long\",\n",
    "                    color=\"Cases\",\n",
    "                    #size=\"Cases\",\n",
    "                     size_max=40,\n",
    "                    size='Cases',\n",
    "                     #size=\"Cases\",\n",
    "                     title=\"Coronavirus Cases by Day (U.S))\",\n",
    "                     \n",
    "                   hover_name=\"name\", \n",
    "                     #labels=\"name\",\n",
    "                  #  color_continuous_scale=px.colors.sequential.RdBu[::-1],\n",
    "                    # color_continuous_scale=px.colors.sequential.RdBu[::-1],\n",
    "                     # color_continuous_scale=px.colors.sequential.Plasma,\n",
    "                     #plotly.express.colors.diverging\n",
    "                    animation_frame=\"Date\"\n",
    "                   \n",
    "                    \n",
    "                    \n",
    "                    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top=final_df_international[final_df_international['Country/Region'].isin(['Republic of Korea','Italy','Iran (Islamic Republic of)','Japan','France','Germany','Spain'\n",
    ",'Singapore'\n",
    ",'Hong Kong'\n",
    ",'Kuwait'\n",
    ",'Switzerland'\n",
    ",'UK'\n",
    "])]\n",
    "df_top.head()\n",
    "\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### International Cases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_international=final_df[final_df['Country/Region']!='China']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of ex Mainland cases (total)\n",
    "\n",
    "\n",
    "#exlcude Mainland China cases for international cases\n",
    "#final_df_international=final_df[final_df['Country/Region']!='Mainland China']\n",
    "\n",
    "final_df_international['total_cases']=final_df_international['Cases'].groupby(final_df_international['Date']).transform('sum')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#df_international=final_df_international[final_df_international['Country/Region'].isin(['South Korea','Italy','Iran','Japan','France','Germany','Spain'\n",
    "\n",
    "           \n",
    "#df_international=df[-df[\"column\"].isin([\"value\"])]\n",
    "                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.line(final_df_international,title=\"International Cases outside Mainland China\", x=\"Date\", y=\"total_cases\", color=\"name\", line_group=\"name\", render_mode=\"svg\")\n",
    "fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"name=\", \"\")))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_international['total_cases']=final_df_international['Cases'].groupby(final_df_international['Date']).transform('sum')\n",
    "final_df_international"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n",
    "#filter out double France and UK cases\n",
    "\n",
    "Euro_list=[' Austria', ' Belgium', ' Bosnia and Herzegovina', ' Cyprus', ' Czech Republic', ' Denmark', ' Finland', ' France', ' Germany', ' Gibraltar', ' Hungary', ' Iceland', ' Ireland', ' Italy', ' Malta', ' Netherlands', ' Norway', ' Poland', ' Portugal', ' Spain', ' Sweden', ' Switzerland', ' United Kingdom', ' Albania', ' Bulgaria', ' Channel Islands', ' Faroe Islands', ' Greece', ' Liechtenstein', ' North Macedonia', ' Romania'\n",
    "\n",
    "]\n",
    "\n",
    "final_df_Euro=final_df_international[final_df_international['name'].isin(Euro_list)]\n",
    "final_df_Euro['total_cases']=final_df_Euro['Cases'].groupby(final_df_Euro['Date']).transform('sum')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.line(final_df_Euro,title=\"Euro Cases\", x=\"Date\", y=\"total_cases\", color=\"name\", line_group=\"name\", render_mode=\"svg\")\n",
    "fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"name=\", \"\")))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot of Euro cases by country\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.line(final_df_Euro,title=\"Euro Cases\", x=\"Date\", y=\"Cases\", color=\"name\", line_group=\"name\", hover_name=\"name\",render_mode=\"svg\")\n",
    "fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"name=\", \"\")))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euro Delta_Cases\n",
    "\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.line(final_df_Euro,title=\"Day on Day Delta Euro Cases\", x=\"Date\", y=\"Delta_Cases\", color=\"name\", line_group=\"name\", hover_name=\"name\",render_mode=\"svg\")\n",
    "fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"name=\", \"\")))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define UK dataframe\n",
    "\n",
    "UK_list=[ 'United Kingdom United Kingdom']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "final_df_UK=final_df_international[final_df_international['name'].isin(UK_list)]\n",
    "\n",
    "#filter out double France and UK cases\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "final_df_UK['total_cases']=final_df_UK['Cases'].groupby(final_df_UK['Date']).transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot of UK cases\n",
    "\n",
    "\n",
    "\n",
    "US_list=[  ' US']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "final_df_US=final_df_international[final_df_international['name'].isin(US_list)]\n",
    "\n",
    "#filter out double France and UK cases\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.line(final_df_US,title=\"New Covid-19 Cases (US)\", x=\"Date\", y=\"Delta_Cases\", color=\"name\", line_group=\"name\", hover_name=\"name\",render_mode=\"svg\")\n",
    "fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"name=\", \"\")))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#X_list=[ ' Italy', ' Spain', ' Germany', ' France', ' United Kingdom',' Netherlands', ' Sweden']\n",
    "\n",
    "#y_list=[' France',' Germany', ' Hungary',' Italy',' Netherlands',' Poland',' Spain',' United Kingdom']\n",
    "\n",
    "\n",
    "y_list=[' Germany', ' Italy',' Spain',' France',' United Kingdom', ' Netherlands', ' Belgium', ' Sweden']\n",
    "\n",
    "\n",
    "final_df_EuroX=final_df_international[final_df_international['name'].isin(y_list)]\n",
    "\n",
    "#filter out double France and UK cases\n",
    "final_df_EuroX['total_cases']=final_df_EuroX['Cases'].groupby(final_df_EuroX['Date']).transform('sum')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.line(final_df_EuroX,title=\"New Covid-19 Cases (Euro)\", x=\"Date\", y=\"Delta_Cases\", color=\"name\", line_group=\"name\", hover_name=\"name\",render_mode=\"svg\")\n",
    "fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"name=\", \"\")))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_EuroX['total_Delta_Cases']=final_df_EuroX['Delta_Cases'].groupby(final_df_EuroX['Date']).transform('sum')\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.line(final_df_EuroX,title=\"New Covid-19 Cases (Euro)\", x=\"Date\", y=\"total_Delta_Cases\", color=\"name\", line_group=\"name\", render_mode=\"svg\")\n",
    "fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"name=\", \"\")))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Latam_list=[' Argentina', ' Brazil',' Chile',' Colombia',' Mexico',' Venezuela']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "final_df_Latam=final_df_international[final_df_international['name'].isin(Latam_list)]\n",
    "\n",
    "#filter out double France and UK cases\n",
    "\n",
    "\n",
    "final_df_Latam['total_cases']=final_df_Latam['Cases'].groupby(final_df_Latam['Date']).transform('sum')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.line(final_df_Latam,title=\"New Cases (Latam)\", x=\"Date\", y=\"Delta_Cases\", color=\"name\", line_group=\"name\", hover_name=\"name\",render_mode=\"svg\")\n",
    "fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"name=\", \"\")))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "East_list=[' United Arab Emirates', ' Saudi Arabia',' India',' Iran',' Japan',' Korea, South',' Taiwan*',' Thailand',' Vietnam']\n",
    "\n",
    "\n",
    "final_df_Asia=final_df_international[final_df_international['name'].isin(East_list)]\n",
    "\n",
    "#filter out double France and UK cases\n",
    "\n",
    "\n",
    "final_df_Asia['total_cases']=final_df_Asia['Cases'].groupby(final_df_Asia['Date']).transform('sum')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.line(final_df_Asia,title=\"New Cases (East ex China)\", x=\"Date\", y=\"Delta_Cases\", color=\"name\", line_group=\"name\", hover_name=\"name\",render_mode=\"svg\")\n",
    "fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"name=\", \"\")))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  U.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cases U.S (aggregate)\n",
    "\n",
    "#final_df_US=final_df[~final_df['Province/State'].str.contains('County')]\n",
    "\n",
    "\n",
    "\n",
    "final_df_US=final_df[(final_df['Country/Region']=='US') & (~final_df['Province/State'].str.contains('County'))& (~final_df['Province/State'].str.contains(','))]\n",
    "\n",
    "\n",
    "final_df_US['total_cases']=final_df_US['Cases'].groupby(final_df_US['Date']).transform('sum')\n",
    "\n",
    "\n",
    "#df = df.loc[(df['Source airport'].isin(['LCY','LHR','LGW','LTN','STN','SEN'])) | (df['Destination airport'].isin(['LCY','LHR','LGW','LTN','STN','SEN']))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.line(final_df_US,title=\"New Covid-19 Cases (US)\", x=\"Date\", y=\"Delta_Cases\", color=\"name\", line_group=\"name\", hover_name=\"name\",render_mode=\"svg\")\n",
    "fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"name=\", \"\")))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### China"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_MChina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select provinces\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "Chinay_list=['Guangdong China', 'Henan China','Hunan China','Shandong China','Zhejiang China']\n",
    "\n",
    "\n",
    "final_df_MChinaX=final_df_MChina[final_df_MChina['name'].isin(Chinay_list)]\n",
    "\n",
    "fig = px.line(final_df_MChinaX,title=\"New Cases Selected Provinces (China)\", x=\"Date\", y=\"Delta_Cases\", color=\"name\", line_group=\"name\", render_mode=\"svg\")\n",
    "fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"name=\", \"\")))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total cases China\n",
    "\n",
    "final_df_MChina['total_Delta_Cases']=final_df_MChina['Delta_Cases'].groupby(final_df_MChina['Date']).transform('sum')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.line(final_df_MChina,title=\"New Cases (China)\", x=\"Date\", y=\"total_Delta_Cases\", color=\"name\", line_group=\"name\", render_mode=\"svg\")\n",
    "fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"name=\", \"\")))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(final_df_EuroX,title=\"Euro Cases\", x=\"Date\", y=\"total_cases\", color=\"name\", line_group=\"name\", render_mode=\"svg\")\n",
    "fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"name=\", \"\")))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top=final_df_international[final_df_international['Country/Region'].isin(['Korea, South','Italy','Iran','Japan','France','Germany','Spain'\n",
    ",'Singapore'\n",
    ",'Hong Kong'\n",
    ",'Kuwait'\n",
    ",'Switzerland'\n",
    ",'UK'\n",
    "])]\n",
    "df_top.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# plot of international cases- \n",
    "\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.line(df_top,title=\"International Cases (top 12)\", x=\"Date\", y=\"Cases\", color=\"name\", line_group=\"name\", hover_name=\"name\",render_mode=\"svg\")\n",
    "fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"name=\", \"\")))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define exponential function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "def func(x, a, b):\n",
    "    return a * np.exp(b * x) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conf range https://lmfit.github.io/lmfit-py/model.html\n",
    "\n",
    "Cases=final_df_MChina_Hubei['Cases']\n",
    "Days=final_df_MChina_Hubei['Day']\n",
    "\n",
    "#empirical data\n",
    "xdata = Days\n",
    "y = Cases\n",
    "ydata = y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "popt, pcov = curve_fit(func, xdata, ydata)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "ax.plot(xdata, func(xdata, *popt), 'r-',label='Exp Model: a=%5.3f, b=%5.3f' % tuple(popt))\n",
    "ax.plot(xdata, ydata, 'b-', label='Reported Cases')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Cases')\n",
    "ax.set_title('Hubei Coronavirus Cases by Day')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_MChina_Hubei.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting Future Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "final_df_MChina_Hubei['y']=final_df_MChina_Hubei['Cases']\n",
    "final_df_MChina_Hubei['ds']=final_df_MChina_Hubei['Date']\n",
    "\n",
    "\n",
    "#Guangdong\n",
    "final_df_MChina_Guangdong['y']=final_df_MChina_Guangdong['Cases']\n",
    "final_df_MChina_Guangdong['ds']=final_df_MChina_Guangdong['Date']\n",
    "\n",
    "#Zhejiang\n",
    "final_df_MChina_Zhejiang['y']=final_df_MChina_Zhejiang['Cases']\n",
    "final_df_MChina_Zhejiang['ds']=final_df_MChina_Zhejiang['Date']\n",
    "\n",
    "#Henan\n",
    "final_df_MChina_Henan['y']=final_df_MChina_Henan['Cases']\n",
    "final_df_MChina_Henan['ds']=final_df_MChina_Henan['Date']\n",
    "\n",
    "#Hunan\n",
    "final_df_MChina_Hunan['y']=final_df_MChina_Hunan['Cases']\n",
    "final_df_MChina_Hunan['ds']=final_df_MChina_Hunan['Date']\n",
    "\n",
    "#Anhui\n",
    "final_df_MChina_Anhui['y']=final_df_MChina_Anhui['Cases']\n",
    "final_df_MChina_Anhui['ds']=final_df_MChina_Anhui['Date']\n",
    "\n",
    "#Jiangxi\n",
    "final_df_MChina_Jiangxi['y']=final_df_MChina_Jiangxi['Cases']\n",
    "final_df_MChina_Jiangxi['ds']=final_df_MChina_Jiangxi['Date']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fbprophet import Prophet\n",
    "from fbprophet.plot import add_changepoints_to_plot\n",
    "\n",
    "\n",
    "#NOTE, DEFAULT changepoint_prior_scale IS 0.05, DECREASING makes less flexible, INCREASIGN makes more flexible\n",
    "changepoint_prior_scale_new=0.05\n",
    "periods_new=30\n",
    "\n",
    "\n",
    "df_Hubei=final_df_MChina_Hubei\n",
    "gm_prophet = Prophet(interval_width=0.95, changepoint_prior_scale=changepoint_prior_scale_new)\n",
    "gm_prophet.fit(df_Hubei)\n",
    "future = gm_prophet.make_future_dataframe(periods=periods_new)\n",
    "\n",
    "\n",
    "\n",
    "#Guangdong\n",
    "\n",
    "df_Guangdong=final_df_MChina_Guangdong\n",
    "gm_prophet_Guangdong = Prophet(interval_width=0.95, changepoint_prior_scale=changepoint_prior_scale_new)\n",
    "gm_prophet_Guangdong.fit(df_Guangdong)\n",
    "future_Guangdong = gm_prophet_Guangdong.make_future_dataframe(periods=periods_new)\n",
    "\n",
    "\n",
    "#Zhejiang\n",
    "df_Zhejiang=final_df_MChina_Zhejiang\n",
    "gm_prophet_Zhejiang = Prophet(interval_width=0.95, changepoint_prior_scale=changepoint_prior_scale_new)\n",
    "gm_prophet_Zhejiang.fit(df_Zhejiang)\n",
    "future_Zhejiang = gm_prophet_Zhejiang.make_future_dataframe(periods=periods_new)\n",
    "\n",
    "\n",
    "#Henan\n",
    "df_Henan=final_df_MChina_Henan\n",
    "gm_prophet_Henan = Prophet(interval_width=0.95, changepoint_prior_scale=changepoint_prior_scale_new)\n",
    "gm_prophet_Henan.fit(df_Henan)\n",
    "future_Henan = gm_prophet_Henan.make_future_dataframe(periods=periods_new)\n",
    "\n",
    "\n",
    "\n",
    "#Hunan\n",
    "df_Hunan=final_df_MChina_Hunan\n",
    "gm_prophet_Hunan = Prophet(interval_width=0.95, changepoint_prior_scale=changepoint_prior_scale_new)\n",
    "gm_prophet_Hunan.fit(df_Hunan)\n",
    "future_Hunan = gm_prophet_Hunan.make_future_dataframe(periods=periods_new)\n",
    "\n",
    "\n",
    "#Anhui\n",
    "df_Anhui=final_df_MChina_Anhui\n",
    "gm_prophet_Anhui = Prophet(interval_width=0.95, changepoint_prior_scale=changepoint_prior_scale_new)\n",
    "gm_prophet_Anhui.fit(df_Anhui)\n",
    "future_Anhui = gm_prophet_Anhui.make_future_dataframe(periods=periods_new)\n",
    "\n",
    "\n",
    "#Jiangxi\n",
    "df_Jiangxi=final_df_MChina_Jiangxi\n",
    "gm_prophet_Jiangxi = Prophet(interval_width=0.95, changepoint_prior_scale=changepoint_prior_scale_new)\n",
    "gm_prophet_Jiangxi.fit(df_Jiangxi)\n",
    "future_Jiangxi = gm_prophet_Jiangxi.make_future_dataframe(periods=periods_new)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create forecast with upper and lower bounds\n",
    "forecast = gm_prophet.predict(future)\n",
    "#forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n",
    "\n",
    "#Guangdong\n",
    "forecast_Guangdong = gm_prophet_Guangdong.predict(future_Guangdong)\n",
    "\n",
    "\n",
    "#Zhejiang\n",
    "forecast_Zhejiang = gm_prophet_Zhejiang.predict(future_Zhejiang)\n",
    "\n",
    "#Henan\n",
    "\n",
    "forecast_Henan = gm_prophet_Henan.predict(future_Henan)\n",
    "\n",
    "#Hunan\n",
    "forecast_Hunan = gm_prophet_Hunan.predict(future_Hunan)\n",
    "\n",
    "\n",
    "#Anhui\n",
    "forecast_Anhui = gm_prophet_Anhui.predict(future_Anhui)\n",
    "\n",
    "#Jiangxi\n",
    "forecast_Jiangxi = gm_prophet_Jiangxi.predict(future_Jiangxi)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig_Guangdong = gm_prophet_Guangdong.plot(forecast_Guangdong)\n",
    "changepoints_Guangdong = add_changepoints_to_plot(fig_Guangdong.gca(), gm_prophet_Guangdong, forecast_Guangdong)\n",
    "\n",
    "\n",
    "fig_Zhejiang = gm_prophet_Zhejiang.plot(forecast_Zhejiang)\n",
    "changepoints_Zhejiang = add_changepoints_to_plot(fig_Zhejiang.gca(), gm_prophet_Zhejiang, forecast_Zhejiang)\n",
    "\n",
    "fig_Henan = gm_prophet_Henan.plot(forecast_Henan)\n",
    "changepoints_Henan = add_changepoints_to_plot(fig_Henan.gca(), gm_prophet_Henan, forecast_Henan)\n",
    "\n",
    "\n",
    "fig_Hunan = gm_prophet_Hunan.plot(forecast_Hunan)\n",
    "changepoints_Hunan = add_changepoints_to_plot(fig_Hunan.gca(), gm_prophet_Hunan, forecast_Hunan)\n",
    "\n",
    "\n",
    "fig_Anhui = gm_prophet_Anhui.plot(forecast_Anhui)\n",
    "changepoints_Anhui = add_changepoints_to_plot(fig_Anhui.gca(), gm_prophet_Anhui, forecast_Anhui)\n",
    "\n",
    "\n",
    "fig_Jiangxi = gm_prophet_Jiangxi.plot(forecast_Jiangxi)\n",
    "changepoints_Jiangxi = add_changepoints_to_plot(fig_Jiangxi.gca(), gm_prophet_Jiangxi, forecast_Jiangxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing trajectory of new cases for various provinces (Mainland China)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot major provinces showing similar change in trend (after redfinition of \"infected\")\n",
    "#https://www.taiwannews.com.tw/en/news/3874490\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "\n",
    "ax1 = fig.add_subplot(4, 1, 1)\n",
    "gm_prophet_Anhui.plot(forecast_Anhui, ax=ax1)\n",
    "ax1.set_title('Anhui, Confirmed Coronavirus Cases')\n",
    "changepoints = add_changepoints_to_plot(fig.gca(), gm_prophet_Anhui, forecast_Anhui)\n",
    "\n",
    "\n",
    "\n",
    "ax2 = fig.add_subplot(4, 1, 2)\n",
    "gm_prophet_Guangdong.plot(forecast_Guangdong, ax=ax2)\n",
    "changepoints_Guangdong = add_changepoints_to_plot(fig.gca(), gm_prophet_Guangdong, forecast_Guangdong)\n",
    "ax2.set_title('Guangdong, Confirmed Coronavirus Cases')\n",
    "\n",
    "ax3 = fig.add_subplot(4, 1, 3)\n",
    "changepoints_Henan = add_changepoints_to_plot(fig.gca(), gm_prophet_Henan, forecast_Henan)\n",
    "gm_prophet_Henan.plot(forecast_Henan, ax=ax3)\n",
    "ax3.set_title('Henan, Confirmed Coronavirus Cases')\n",
    "\n",
    "\n",
    "\n",
    "ax4 = fig.add_subplot(4, 1, 4)\n",
    "changepoints_Hunan = add_changepoints_to_plot(fig.gca(), gm_prophet_Hunan, forecast_Hunan)\n",
    "gm_prophet_Hunan.plot(forecast_Hunan, ax=ax4)\n",
    "ax4.set_title('Hunan, Confirmed Coronavirus Cases')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "axes = fig.get_axes()\n",
    "axes[0].set_xlabel('')\n",
    "axes[0].set_ylabel('Cases')\n",
    "axes[1].set_xlabel('')\n",
    "axes[1].set_ylabel('Cases')\n",
    "axes[2].set_xlabel('')\n",
    "axes[2].set_ylabel('Cases')\n",
    "axes[3].set_xlabel('Date')\n",
    "axes[3].set_ylabel('Cases')\n",
    "\n",
    "fig.savefig('temp.png', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = gm_prophet.plot(forecast)\n",
    "plt.title('Hubei Coronavirus Cases by Day, actual and forecasted');\n",
    "axes = fig1.get_axes()\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Cases')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added change points to forecast\n",
    "from fbprophet.plot import add_changepoints_to_plot\n",
    "fig2= gm_prophet.plot(forecast)\n",
    "a = add_changepoints_to_plot(fig2.gca(), gm_prophet, forecast)\n",
    "plt.title('Hubei Coronavirus Cases by Day, actual and forecasted with changepoints');\n",
    "axes = fig2.get_axes()\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Cases')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast International Cases (ex Mainland China)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_international['Date'][30:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_international_adjust = final_df_international[(final_df_international['Date'] > '2/23/20') ]\n",
    "final_df_international_adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df_international_adjust = final_df_international[(final_df_international['Date'] > '2020-02-20') ]\n",
    "final_df_international_adjust['y']=final_df_international_adjust['total_cases']\n",
    "final_df_international_adjust['ds']=final_df_international_adjust['Date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet\n",
    "from fbprophet.plot import add_changepoints_to_plot\n",
    "\n",
    "#NOTE, DEFAULT changepoint_prior_scale IS 0.05, DECREASING makes less flexible, INCREASIGN makes more flexible\n",
    "\n",
    "changepoint_prior_scale_new_int=0.05\n",
    "periods_new_int=30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Hubei=final_df_MChina_Hubei\n",
    "gm_prophet_int = Prophet(interval_width=0.95, changepoint_prior_scale=changepoint_prior_scale_new_int)\n",
    "gm_prophet_int.fit(final_df_international_adjust)\n",
    "future_int = gm_prophet_int.make_future_dataframe(periods=periods_new_int)\n",
    "\n",
    "forecast_int = gm_prophet_int.predict(future_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added change points to forecast\n",
    "from fbprophet.plot import add_changepoints_to_plot\n",
    "fig2= gm_prophet_int.plot(forecast_int)\n",
    "a = add_changepoints_to_plot(fig2.gca(), gm_prophet_int, forecast_int)\n",
    "plt.title('International Coronavirus Cases by Day, actual and forecasted with changepoints');\n",
    "axes = fig2.get_axes()\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Cases')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions of Euro Countries (changepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_Euro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_France = final_df_Euro[final_df_Euro['name']== 'France France']\n",
    "df_France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#define country DFs\n",
    "\n",
    "\n",
    "Euro_list=[' Austria', ' Belgium', ' Bosnia and Herzegovina', ' Cyprus', ' Czech Republic', ' Denmark', ' Finland', ' France', ' Germany', ' Gibraltar', ' Hungary', ' Iceland', ' Ireland', ' Italy', ' Malta', ' Netherlands', ' Norway', ' Poland', ' Portugal', ' Spain', ' Sweden', ' Switzerland', ' United Kingdom', ' Albania', ' Bulgaria', ' Channel Islands', ' Faroe Islands', ' Greece', ' Liechtenstein', ' North Macedonia', ' Romania'\n",
    "\n",
    "]\n",
    "\n",
    "final_df_Euro=final_df_international[final_df_international['name'].isin(Euro_list)]\n",
    "\n",
    "\n",
    "# France\n",
    "df_France = final_df_Euro[final_df_Euro['name']== ' France']\n",
    "df_France['y']= df_France['Cases']\n",
    "df_France['ds']= df_France['Date']\n",
    "\n",
    "#UK\n",
    "df_UK= final_df_Euro[final_df_Euro['name']== ' United Kingdom']\n",
    "df_UK['y']= df_UK['Cases']\n",
    "df_UK['ds']= df_UK['Date']\n",
    "\n",
    "# Italy \n",
    "df_Italy = final_df_Euro [final_df_Euro['name']== ' Italy']\n",
    "df_Italy['y']= df_Italy['Cases']\n",
    "df_Italy['ds']= df_Italy['Date']\n",
    "\n",
    "#Spain\n",
    "df_Spain = final_df_Euro [final_df_Euro['name']== ' Spain']\n",
    "df_Spain['y']= df_Spain['Cases']\n",
    "df_Spain['ds']= df_Spain['Date']\n",
    "\n",
    "#Germany\n",
    "df_Germany = final_df_Euro [final_df_Euro['name']== ' Germany']\n",
    "df_Germany['y']= df_Germany['Cases']\n",
    "df_Germany['ds']= df_Germany['Date']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "from fbprophet import Prophet\n",
    "from fbprophet.plot import add_changepoints_to_plot\n",
    "\n",
    "\n",
    "#NOTE, DEFAULT changepoint_prior_scale IS 0.05, DECREASING makes less flexible, INCREASIGN makes more flexible\n",
    "changepoint_prior_scale_new2=0.2\n",
    "periods_new=30\n",
    "\n",
    "\n",
    "#France\n",
    "gm_prophet_France = Prophet(interval_width=0.95, changepoint_prior_scale=changepoint_prior_scale_new2)\n",
    "gm_prophet_France.fit(df_France)\n",
    "future_France = gm_prophet_France.make_future_dataframe(periods=periods_new)\n",
    "\n",
    "#UK\n",
    "gm_prophet_UK = Prophet(interval_width=0.95, changepoint_prior_scale=changepoint_prior_scale_new2)\n",
    "gm_prophet_UK.fit(df_UK)\n",
    "future_UK = gm_prophet_UK.make_future_dataframe(periods=periods_new)\n",
    "\n",
    "\n",
    "# Italy \n",
    "\n",
    "gm_prophet_Italy = Prophet(interval_width=0.95, changepoint_prior_scale=changepoint_prior_scale_new2)\n",
    "gm_prophet_Italy.fit(df_Italy)\n",
    "future_Italy = gm_prophet_Italy.make_future_dataframe(periods=periods_new)\n",
    "\n",
    "#Spain\n",
    "\n",
    "gm_prophet_Spain = Prophet(interval_width=0.95, changepoint_prior_scale=changepoint_prior_scale_new2)\n",
    "gm_prophet_Spain.fit(df_Spain)\n",
    "future_Spain = gm_prophet_Spain.make_future_dataframe(periods=periods_new)\n",
    "\n",
    "\n",
    "#Germany\n",
    "\n",
    "gm_prophet_Germany = Prophet(interval_width=0.95, changepoint_prior_scale=changepoint_prior_scale_new2)\n",
    "gm_prophet_Germany.fit(df_Germany)\n",
    "future_Germany = gm_prophet_Germany.make_future_dataframe(periods=periods_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create forecast with upper and lower bounds\n",
    "forecast = gm_prophet.predict(future)\n",
    "#forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n",
    "\n",
    "#France\n",
    "forecast_France = gm_prophet_France.predict(future_France)\n",
    "\n",
    "#UK\n",
    "forecast_UK = gm_prophet_UK.predict(future_UK)\n",
    "\n",
    "#Italy\n",
    "forecast_Italy = gm_prophet_Italy.predict(future_Italy)\n",
    "\n",
    "#Spain\n",
    "forecast_Spain = gm_prophet_Spain.predict(future_Spain)\n",
    "\n",
    "# Germany \n",
    "forecast_Germany = gm_prophet_Germany.predict(future_Germany)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create figures\n",
    "\n",
    "#France\n",
    "fig_France = gm_prophet_France.plot(forecast_France)\n",
    "changepoints_France = add_changepoints_to_plot(fig_France.gca(), gm_prophet_France, forecast_France)\n",
    "\n",
    "#UK\n",
    "fig_UK = gm_prophet_UK.plot(forecast_UK)\n",
    "changepoints_UK = add_changepoints_to_plot(fig_UK.gca(), gm_prophet_UK, forecast_UK)\n",
    "\n",
    "\n",
    "#Italy\n",
    "fig_Italy = gm_prophet_Italy.plot(forecast_Italy)\n",
    "changepoints_Italy = add_changepoints_to_plot(fig_Italy.gca(), gm_prophet_Italy, forecast_Italy)\n",
    "\n",
    "\n",
    "#Spain\n",
    "fig_Spain = gm_prophet_Spain.plot(forecast_Spain)\n",
    "changepoints_Spain = add_changepoints_to_plot(fig_Spain.gca(), gm_prophet_Spain, forecast_Spain)\n",
    "\n",
    "# Germany \n",
    "fig_Germany = gm_prophet_Germany.plot(forecast_Germany)\n",
    "changepoints_Germany = add_changepoints_to_plot(fig_Germany.gca(), gm_prophet_Germany, forecast_Germany)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet.plot import add_changepoints_to_plot\n",
    "fig2= gm_prophet_France.plot(forecast_France)\n",
    "a = add_changepoints_to_plot(fig2.gca(), gm_prophet_France, forecast_France)\n",
    "plt.title('France Coronavirus Cases by Day, actual and forecasted with changepoints');\n",
    "axes = fig2.get_axes()\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fbprophet.plot import add_changepoints_to_plot\n",
    "fig2= gm_prophet_UK.plot(forecast_UK)\n",
    "a = add_changepoints_to_plot(fig2.gca(), gm_prophet_UK, forecast_UK)\n",
    "plt.title('UK Coronavirus Cases by Day, actual and forecasted with changepoints');\n",
    "axes = fig2.get_axes()\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fbprophet.plot import add_changepoints_to_plot\n",
    "fig2= gm_prophet_Spain.plot(forecast_Spain)\n",
    "a = add_changepoints_to_plot(fig2.gca(), gm_prophet_Spain, forecast_Spain)\n",
    "plt.title('Spain Coronavirus Cases by Day, actual and forecasted with changepoints');\n",
    "axes = fig2.get_axes()\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fbprophet.plot import add_changepoints_to_plot\n",
    "fig2= gm_prophet_Italy.plot(forecast_Italy)\n",
    "a = add_changepoints_to_plot(fig2.gca(), gm_prophet_Italy, forecast_Italy)\n",
    "plt.title('Italy Coronavirus Cases by Day, actual and forecasted with changepoints');\n",
    "axes = fig2.get_axes()\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from fbprophet.plot import add_changepoints_to_plot\n",
    "fig2= gm_prophet_Germany.plot(forecast_Germany)\n",
    "a = add_changepoints_to_plot(fig2.gca(), gm_prophet_Germany, forecast_Germany)\n",
    "plt.title('Germany Coronavirus Cases by Day, actual and forecasted with changepoints');\n",
    "axes = fig2.get_axes()\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Cases')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.line(final_df_international,title=\"International Cases outside Mainland China\", x=\"Date\", y=\"total_cases\", color=\"name\", line_group=\"name\", render_mode=\"svg\")\n",
    "fig.for_each_trace(lambda t: t.update(name=t.name.replace(\"name=\", \"\")))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flights Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pcfg.eu/posts/how-to-plot-flight-routes-using-plotly/\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "#import plotly.plotly as py\n",
    "import plotly.offline as ol\n",
    "from geographiclib.geodesic import Geodesic\n",
    "geod = Geodesic.WGS84\n",
    "\n",
    "# Define function to calculate distance (in meters) between two points\n",
    "def dist(p1Lat, p1Lon, p2Lat, p2Lon):\n",
    "    return geod.Inverse(p1Lat, p1Lon, p2Lat, p2Lon, Geodesic.DISTANCE)['s12']\n",
    "\n",
    "# Read the data into a dataframe (specifying the column names)\n",
    "\n",
    "#read_conf = pd.read_csv('/Users/neil.watt/Documents/PythonScripts/Coronavirus/coronavirus_stats_conf2.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "\n",
    "#df = pd.read_csv('routes.dat', sep=',', header=None,\n",
    " #                names=['Airline','Airline ID','Source airport','Source airport ID',\n",
    "  #                      'Destination airport','Destination airport ID','Codeshare',\n",
    "   #                     'Stops','Equipment'])\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('/Users/neil.watt/Documents/PythonScripts/Coronavirus/routes.dat.txt',sep=',', header=None,\n",
    "                 names=['Airline','Airline ID','Source airport','Source airport ID',\n",
    "                        'Destination airport','Destination airport ID','Codeshare',\n",
    "                        'Stops','Equipment'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates (only one trajectory per route)\n",
    "df = df[['Source airport','Destination airport']].drop_duplicates(keep='first', inplace=False)\n",
    "\n",
    "# Read the data into a dataframe (specifying the column names)\n",
    "df_airports = pd.read_csv('/Users/neil.watt/Documents/PythonScripts/Coronavirus/airports.dat.txt', sep=',', header=None,\n",
    "                          names=['Airport','Name','City','Country','IATA','ICAO',\n",
    "                                 'Latitude','Longitude','Altitude','Timezone','DST',\n",
    "                                 'Tz','Type','Source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALL LONDON AIRPORTS\n",
    "\n",
    "# Select only those routes starting or ending from a London Airport\n",
    "# in order London City, Heathrow, Gatwick, Luton, Stansted, Southend\n",
    "df = df.loc[(df['Source airport'].isin(['LCY','LHR','LGW','LTN','STN','SEN'])) | (df['Destination airport'].isin(['LCY','LHR','LGW','LTN','STN','SEN']))]\n",
    "\n",
    "# Append the origin airport's coordinates to the routes' dataframe\n",
    "df = pd.merge(df, df_airports[['IATA','Latitude','Longitude']],\n",
    "              how='inner', left_on='Source airport', right_on='IATA', suffixes=('_Orig','_Dest'))\n",
    "\n",
    "# Append the destination airport's coordinates to the routes' dataframe\n",
    "df = pd.merge(df, df_airports[['IATA','Latitude','Longitude']],\n",
    "              how='inner', left_on='Destination airport', right_on='IATA', suffixes=('_Orig','_Dest'))\n",
    "\n",
    "# Keep only Origin/Destination IATA ID columns, and their Latitude/Longitude\n",
    "df = df.drop(columns=['Source airport','Destination airport'])\n",
    "\n",
    "# Calculate the distance (great circle distance) between the origin and destination airports\n",
    "df['Distance'] = ''\n",
    "for index, row in df.iterrows():\n",
    "    df.loc[df.index==index,'Distance'] = dist(row.Latitude_Orig, row.Longitude_Orig, row.Latitude_Dest, row.Longitude_Dest)/1000\n",
    "\n",
    "# Initialise the data list that will be used to feed the plot\n",
    "data = []\n",
    "\n",
    "# Append all airports (blue dots) to the map\n",
    "data.append(dict(\n",
    "                type = 'scattergeo',\n",
    "                locationmode = 'ISO-3',\n",
    "                showlegend = False,\n",
    "                lon = df_airports['Longitude'],\n",
    "                lat = df_airports['Latitude'],\n",
    "                hoverinfo = 'text',\n",
    "                text = df_airports['IATA'],\n",
    "                mode = 'markers',\n",
    "                marker = dict(\n",
    "                    size=2,\n",
    "                    color='rgb(0, 0, 255)',\n",
    "                    line = dict(\n",
    "                        width=3,\n",
    "                        color='rgba(68, 68, 68, 0)'\n",
    "                    )\n",
    "                ))\n",
    "        )\n",
    "\n",
    "# Append the longest route to the map\n",
    "data.append(\n",
    "        dict(\n",
    "            type = 'scattergeo',\n",
    "            locationmode = 'ISO-3',\n",
    "            name = 'Longest Route',\n",
    "            showlegend = True,\n",
    "            lon = [ df.loc[df['Distance']==df['Distance'].max(),'Longitude_Orig'].values[0], df.loc[df['Distance']==df['Distance'].max(),'Longitude_Dest'].values[0] ],\n",
    "            lat = [ df.loc[df['Distance']==df['Distance'].max(),'Latitude_Orig'].values[0], df.loc[df['Distance']==df['Distance'].max(),'Latitude_Dest'].values[0] ],\n",
    "            mode = 'lines',\n",
    "            line = dict(\n",
    "                width = 2,\n",
    "                color = 'red',\n",
    "            ),\n",
    "            opacity = 1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Append all other routes to the map\n",
    "for i in range(len(df)):\n",
    "    data.append(\n",
    "        dict(\n",
    "            type = 'scattergeo',\n",
    "            locationmode = 'ISO-3',\n",
    "            name = str(df['IATA_Orig'][i]) + ' - ' + str(df['IATA_Dest'][i]),\n",
    "            showlegend = True if df['IATA_Orig'][i] in ['LCY','LHR','LGW','LTN','STN','SEN'] else False,\n",
    "            lon = [ df['Longitude_Orig'][i], df['Longitude_Dest'][i] ],\n",
    "            lat = [ df['Latitude_Orig'][i], df['Latitude_Dest'][i] ],\n",
    "            mode = 'lines',\n",
    "            line = dict(\n",
    "                width = 1,\n",
    "                color = 'green',\n",
    "            ),\n",
    "            opacity = 0.3,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Define the plot's layout\n",
    "layout = dict(\n",
    "        title = 'Airports and Routes',\n",
    "        showlegend = True,\n",
    "        geo = dict(\n",
    "            scope='world',\n",
    "            projection=dict( type='azimuthal equal area' ),\n",
    "            showland = True,\n",
    "            landcolor = 'rgb(255, 255, 255)',\n",
    "            countrycolor = 'rgb(0, 0, 0)',\n",
    "        ),\n",
    "    )\n",
    "\n",
    "# Create the figure to be plotted\n",
    "fig = dict( data=data, layout=layout )\n",
    "#py.plot(fig, world_readable=True)\n",
    "ol.plot(fig, filename='Airports and routes.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indian Airports\n",
    "\n",
    "\n",
    "df_India=df_airports[df_airports['Country']=='India']\n",
    "India_list=df_India['IATA'].tolist() \n",
    "India_list_new=list(set(India_list))\n",
    "\n",
    "\n",
    "df_Iran=df_airports[df_airports['Country']=='Iran']\n",
    "Iran_list=df_Iran['IATA'].tolist() \n",
    "Iran_list_new=list(set(Iran_list))\n",
    "\n",
    "df_China=df_airports[df_airports['Country']=='China']\n",
    "China_list=df_China['IATA'].tolist() \n",
    "China_list_new=list(set(China_list))\n",
    "\n",
    "df_Italy=df_airports[df_airports['Country']=='Italy']\n",
    "Italy_list=df_Italy['IATA'].tolist() \n",
    "Italy_list_new=list(set(Italy_list))\n",
    "\n",
    "df_UK=df_airports[df_airports['Country']=='United Kingdom']\n",
    "UK_list=df_UK['IATA'].tolist() \n",
    "UK_list_new=list(set(UK_list))\n",
    "\n",
    "#final_df_MChina_Hubei=final_df_MChina[final_df_MChina['Province/State']=='Hubei']\n",
    "\n",
    "#inal_df_MChina_Hubei=final_df_MChina[final_df_MChina['Province/State']=='Hubei']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UK_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['LCY','LHR','LGW','LTN','STN','SEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "#import plotly.plotly as py\n",
    "import plotly.offline as ol\n",
    "from geographiclib.geodesic import Geodesic\n",
    "geod = Geodesic.WGS84\n",
    "\n",
    "# Define function to calculate distance (in meters) between two points\n",
    "def dist(p1Lat, p1Lon, p2Lat, p2Lon):\n",
    "    return geod.Inverse(p1Lat, p1Lon, p2Lat, p2Lon, Geodesic.DISTANCE)['s12']\n",
    "\n",
    "# Read the data into a dataframe (specifying the column names)\n",
    "\n",
    "#read_conf = pd.read_csv('/Users/neil.watt/Documents/PythonScripts/Coronavirus/coronavirus_stats_conf2.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "\n",
    "#df = pd.read_csv('routes.dat', sep=',', header=None,\n",
    " #                names=['Airline','Airline ID','Source airport','Source airport ID',\n",
    "  #                      'Destination airport','Destination airport ID','Codeshare',\n",
    "   #                     'Stops','Equipment'])\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('/Users/neil.watt/Documents/PythonScripts/Coronavirus/routes.dat.txt',sep=',', header=None,\n",
    "                 names=['Airline','Airline ID','Source airport','Source airport ID',\n",
    "                        'Destination airport','Destination airport ID','Codeshare',\n",
    "                        'Stops','Equipment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates (only one trajectory per route)\n",
    "df = df[['Source airport','Destination airport']].drop_duplicates(keep='first', inplace=False)\n",
    "\n",
    "# Read the data into a dataframe (specifying the column names)\n",
    "df_airports = pd.read_csv('/Users/neil.watt/Documents/PythonScripts/Coronavirus/airports.dat.txt', sep=',', header=None,\n",
    "                          names=['Airport','Name','City','Country','IATA','ICAO',\n",
    "                                 'Latitude','Longitude','Altitude','Timezone','DST',\n",
    "                                 'Tz','Type','Source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALL LONDON AIRPORTS\n",
    "\n",
    "# Select only those routes starting or ending from a London Airport\n",
    "# in order London City, Heathrow, Gatwick, Luton, Stansted, Southend\n",
    "\n",
    "Country_List=UK_list_new\n",
    "\n",
    "#India_list_new\n",
    "\n",
    "# note pipemeans OR\n",
    "#df = df.loc[(df['Source airport'].isin(Iran_list_new)) | (df['Destination airport'].isin(India_list_new))]\n",
    "df = df.loc[(df['Source airport'].isin(Country_List)) | (df['Destination airport'].isin(Country_List))]\n",
    "\n",
    "#df = df.loc[(df['Source airport'].isin(['LCY','LHR','LGW','LTN','STN','SEN'])) | (df['Destination airport'].isin(['LCY','LHR','LGW','LTN','STN','SEN']))]\n",
    "\n",
    "# Append the origin airport's coordinates to the routes' dataframe\n",
    "df = pd.merge(df, df_airports[['IATA','Latitude','Longitude']],\n",
    "              how='inner', left_on='Source airport', right_on='IATA', suffixes=('_Orig','_Dest'))\n",
    "\n",
    "# Append the destination airport's coordinates to the routes' dataframe\n",
    "df = pd.merge(df, df_airports[['IATA','Latitude','Longitude']],\n",
    "              how='inner', left_on='Destination airport', right_on='IATA', suffixes=('_Orig','_Dest'))\n",
    "\n",
    "# Keep only Origin/Destination IATA ID columns, and their Latitude/Longitude\n",
    "df = df.drop(columns=['Source airport','Destination airport'])\n",
    "\n",
    "# Calculate the distance (great circle distance) between the origin and destination airports\n",
    "df['Distance'] = ''\n",
    "for index, row in df.iterrows():\n",
    "    df.loc[df.index==index,'Distance'] = dist(row.Latitude_Orig, row.Longitude_Orig, row.Latitude_Dest, row.Longitude_Dest)/1000\n",
    "\n",
    "# Initialise the data list that will be used to feed the plot\n",
    "data = []\n",
    "\n",
    "# Append all airports (blue dots) to the map\n",
    "data.append(dict(\n",
    "                type = 'scattergeo',\n",
    "                locationmode = 'ISO-3',\n",
    "                showlegend = False,\n",
    "                lon = df_airports['Longitude'],\n",
    "                lat = df_airports['Latitude'],\n",
    "                hoverinfo = 'text',\n",
    "                text = df_airports['IATA'],\n",
    "                mode = 'markers',\n",
    "                marker = dict(\n",
    "                    size=2,\n",
    "                    color='rgb(0, 0, 255)',\n",
    "                    line = dict(\n",
    "                        width=3,\n",
    "                        color='rgba(68, 68, 68, 0)'\n",
    "                    )\n",
    "                ))\n",
    "        )\n",
    "\n",
    "# Append the longest route to the map\n",
    "data.append(\n",
    "        dict(\n",
    "            type = 'scattergeo',\n",
    "            locationmode = 'ISO-3',\n",
    "            name = 'Longest Route',\n",
    "            showlegend = True,\n",
    "            lon = [ df.loc[df['Distance']==df['Distance'].max(),'Longitude_Orig'].values[0], df.loc[df['Distance']==df['Distance'].max(),'Longitude_Dest'].values[0] ],\n",
    "            lat = [ df.loc[df['Distance']==df['Distance'].max(),'Latitude_Orig'].values[0], df.loc[df['Distance']==df['Distance'].max(),'Latitude_Dest'].values[0] ],\n",
    "            mode = 'lines',\n",
    "            line = dict(\n",
    "                width = 2,\n",
    "                color = 'red',\n",
    "            ),\n",
    "            opacity = 1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "#India_list_new\n",
    "\n",
    "# Append all other routes to the map\n",
    "for i in range(len(df)):\n",
    "    data.append(\n",
    "        dict(\n",
    "            type = 'scattergeo',\n",
    "            locationmode = 'ISO-3',\n",
    "            name = str(df['IATA_Orig'][i]) + ' - ' + str(df['IATA_Dest'][i]),\n",
    "            #showlegend = True if df['IATA_Orig'][i] in India_list_new else False,\n",
    "            #showlegend = True if df['IATA_Orig'][i] in ['LCY','LHR','LGW','LTN','STN','SEN'] else False,\n",
    "            lon = [ df['Longitude_Orig'][i], df['Longitude_Dest'][i] ],\n",
    "            lat = [ df['Latitude_Orig'][i], df['Latitude_Dest'][i] ],\n",
    "            mode = 'lines',\n",
    "            line = dict(\n",
    "                width = 1,\n",
    "                color = 'green',\n",
    "            ),\n",
    "            opacity = 0.3,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Define the plot's layout\n",
    "layout = dict(\n",
    "        title = 'UK Airports and Routes',\n",
    "      \n",
    "    title_x=0.5,\n",
    "    showlegend = False,\n",
    "        geo = dict(\n",
    "            scope='world',\n",
    "            projection=dict( type='azimuthal equal area' ),\n",
    "            showland = True,\n",
    "            landcolor = 'rgb(255, 255, 255)',\n",
    "           # countrycolor = 'rgb(255, 255, 255)',\n",
    "            showcountries=True, countrycolor=\"Black\"\n",
    "            #showcountries = True,\n",
    "            \n",
    "            \n",
    "        ),\n",
    "    #title='Iran Airports and Routes',\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Create the figure to be plotted\n",
    "fig = dict( data=data, layout=layout )\n",
    "\n",
    "#py.plot(fig, world_readable=True)\n",
    "ol.plot(fig, filename='Airports and routes.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/catching-that-flight-visualizing-social-network-with-networkx-and-basemap-ce4a0d2eaea6\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits\n",
    "import Basemap as Basemap\n",
    "#from mpl_toolkits.basemap import Basemap as Basemap\n",
    "#from mpl_toolkits import Basemap as Basemap\n",
    "#from mpl_toolkits.basemap import Basemap as Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.from_pandas_dataframe(routes_us, source = 'Source Airport', target = 'Dest Airport', edge_attr = 'number of flights',create_using = nx.DiGraph())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
